"""
Parameter Optimizer - Optimizaci√≥n aut√≥noma de TODOS los par√°metros
Usa b√∫squeda adaptativa y meta-learning para encontrar configuraciones √≥ptimas
"""
import numpy as np
import logging
from typing import Dict, List, Any, Tuple
from datetime import datetime
import copy

logger = logging.getLogger(__name__)


class ParameterOptimizer:
    """
    Optimizador aut√≥nomo de par√°metros
    - Modifica TODOS los par√°metros sin limitaciones
    - Usa b√∫squeda inteligente basada en resultados
    - Aprende qu√© cambios funcionan mejor
    - Notifica cada modificaci√≥n a Telegram
    """

    def __init__(self):
        """Inicializa optimizador con rangos de b√∫squeda para cada par√°metro"""

        # Definir rangos de b√∫squeda para TODOS los par√°metros
        # Sin limitaciones - la IA tiene control TOTAL sobre par√°metros listados
        #
        # PAR√ÅMETROS PROTEGIDOS (NO MODIFICABLES POR IA):
        # - PAPER_TRADING_INITIAL_BALANCE: $50,000 USDT (fijo)
        # - STOP_LOSS: Basado en ATR (l√≥gica fija en an√°lisis t√©cnico)
        #
        # PAR√ÅMETROS AHORA OPTIMIZABLES (con l√≠mites conservadores):
        # - TAKE_PROFITS: 0.3-2.0% (din√°micos seg√∫n oportunidad)
        # - News Triggers: thresholds de importance, engagement, social buzz
        # - Multi-Layer Confidence: weights de cada capa
        self.parameter_ranges = {
            # Trading Configuration
            'CHECK_INTERVAL': (60, 300, 'int'),  # 1-5 minutos
            'CONSERVATIVE_THRESHOLD': (3.0, 8.0, 'float'),  # Score threshold
            'FLASH_THRESHOLD': (4.0, 8.0, 'float'),
            'FLASH_MIN_CONFIDENCE': (40, 80, 'int'),
            'PROFIT_THRESHOLD': (0.5, 3.0, 'float'),  # % profit target

            # Technical Indicators
            'RSI_OVERSOLD': (20, 40, 'int'),
            'RSI_OVERBOUGHT': (60, 80, 'int'),
            'RSI_PERIOD': (7, 21, 'int'),
            'MACD_FAST': (8, 16, 'int'),
            'MACD_SLOW': (20, 30, 'int'),
            'MACD_SIGNAL': (7, 12, 'int'),
            'EMA_SHORT': (5, 15, 'int'),
            'EMA_MEDIUM': (15, 30, 'int'),
            'EMA_LONG': (40, 60, 'int'),
            'BB_PERIOD': (15, 25, 'int'),
            'BB_STD': (1.5, 2.5, 'float'),

            # Risk Management
            'BASE_POSITION_SIZE_PCT': (2.0, 8.0, 'float'),
            'MAX_DRAWDOWN_LIMIT': (10.0, 25.0, 'float'),
            'MAX_POSITIONS': (5, 12, 'int'),
            'MAX_RISK_PER_TRADE_PCT': (1.0, 3.0, 'float'),

            # ML Model Hyperparameters
            'N_ESTIMATORS': (100, 300, 'int'),
            'MAX_DEPTH': (3, 7, 'int'),
            'LEARNING_RATE': (0.01, 0.15, 'float'),
            'SUBSAMPLE': (0.6, 0.9, 'float'),
            'COLSAMPLE_BYTREE': (0.6, 0.9, 'float'),
            'MIN_CHILD_WEIGHT': (1, 5, 'int'),
            'GAMMA': (0.0, 0.3, 'float'),
            'REG_ALPHA': (0.0, 0.3, 'float'),
            'REG_LAMBDA': (0.5, 2.0, 'float'),

            # GROWTH API - News-Triggered Trading (NUEVO)
            'NEWS_IMPORTANCE_THRESHOLD': (0.25, 0.55, 'float'),  # % important votes
            'NEWS_ENGAGEMENT_THRESHOLD': (15, 50, 'int'),  # saves + comments
            'SOCIAL_BUZZ_THRESHOLD': (5, 20, 'int'),  # min social posts
            'RECENT_NEWS_WINDOW_MIN': (3, 15, 'int'),  # minutos para "reciente"
            'PRE_PUMP_MIN_SCORE': (65, 90, 'int'),  # score m√≠nimo para pre-pump signal

            # GROWTH API - Multi-Layer Confidence Weights (NUEVO)
            'IMPORTANCE_WEIGHT': (5, 15, 'int'),  # importance layer weight
            'SOCIAL_BUZZ_WEIGHT': (4, 12, 'int'),  # social buzz layer weight
            'MARKET_CAP_WEIGHT': (3, 8, 'int'),  # market cap layer weight

            # Dynamic Take Profits (NUEVO - antes fijos)
            'TP1_BASE_PCT': (0.25, 0.5, 'float'),  # TP1 base (scalping)
            'TP2_BASE_PCT': (0.6, 1.2, 'float'),  # TP2 base (medio)
            'TP3_BASE_PCT': (1.0, 2.0, 'float'),  # TP3 base (agresivo)
            'DYNAMIC_TP_MULTIPLIER': (1.0, 2.5, 'float'),  # multiplicador en oportunidades cr√≠ticas
            'HIGH_CRITICALITY_THRESHOLD': (80, 95, 'int'),  # score para usar TPs altos
        }

        # Historial de configuraciones probadas y sus resultados
        self.trial_history: List[Dict] = []

        # Mejor configuraci√≥n encontrada hasta ahora
        self.best_config: Dict = {}
        self.best_performance: float = -float('inf')

        # Configuraci√≥n actual
        self.current_config: Dict = {}

        # N√∫mero de trials realizados
        self.total_trials = 0

        # Learning: trackear qu√© par√°metros tienen mayor impacto
        self.parameter_importance: Dict[str, float] = {
            param: 1.0 for param in self.parameter_ranges.keys()
        }

        logger.info(f"üéØ Parameter Optimizer inicializado con {len(self.parameter_ranges)} par√°metros optimizables")

    def suggest_parameter_changes(
        self,
        current_performance: Dict,
        exploration_factor: float = 0.3
    ) -> Dict[str, Any]:
        """
        Sugiere cambios de par√°metros basado en performance actual

        Args:
            current_performance: M√©tricas actuales (win_rate, roi, sharpe, etc.)
            exploration_factor: Qu√© tan agresivo explorar (0-1)

        Returns:
            Dict con par√°metros sugeridos y razones
        """
        # Extraer m√©trica clave de performance
        performance_score = self._calculate_performance_score(current_performance)

        logger.info(f"üìä Performance actual: {performance_score:.3f}")

        # Decidir estrategia: explorar vs optimizar
        if np.random.random() < exploration_factor or self.total_trials < 10:
            # EXPLORAR: cambios aleatorios para descubrir nuevas configuraciones
            new_config = self._generate_random_config()
            strategy = "EXPLORATION"
            logger.info("üîç Estrategia: EXPLORACI√ìN (b√∫squeda aleatoria)")
        else:
            # OPTIMIZAR: cambios inteligentes basados en historial
            new_config = self._generate_optimized_config(current_performance)
            strategy = "OPTIMIZATION"
            logger.info("üéØ Estrategia: OPTIMIZACI√ìN (basado en historial)")

        # Identificar qu√© par√°metros cambiaron
        changes = self._identify_changes(self.current_config, new_config)

        # Registrar trial
        self.total_trials += 1

        return {
            'config': new_config,
            'changes': changes,
            'strategy': strategy,
            'trial_number': self.total_trials,
            'reason': self._generate_change_reason(changes, strategy, current_performance)
        }

    def _calculate_performance_score(self, metrics: Dict) -> float:
        """
        Calcula score compuesto de performance
        Combina m√∫ltiples m√©tricas en un solo valor

        Args:
            metrics: Dict con m√©tricas (win_rate, roi, sharpe_ratio, etc.)

        Returns:
            Score de performance (mayor es mejor)
        """
        # Extraer m√©tricas clave
        win_rate = metrics.get('win_rate', 0) / 100.0  # 0-1
        roi = metrics.get('roi', 0) / 100.0  # Normalized
        sharpe = metrics.get('sharpe_ratio', 0)
        profit_factor = metrics.get('profit_factor', 1.0)
        max_drawdown = abs(metrics.get('max_drawdown', 0)) / 100.0  # 0-1

        # Ponderaci√≥n de m√©tricas
        score = (
            win_rate * 0.25 +           # 25% win rate
            roi * 0.30 +                # 30% ROI
            sharpe * 0.15 +             # 15% Sharpe ratio
            (profit_factor - 1) * 0.20 + # 20% Profit factor
            (1 - max_drawdown) * 0.10   # 10% drawdown (invertido)
        )

        return score

    def _generate_random_config(self) -> Dict[str, Any]:
        """Genera configuraci√≥n aleatoria dentro de los rangos permitidos"""
        config = {}

        for param, (min_val, max_val, dtype) in self.parameter_ranges.items():
            if dtype == 'int':
                config[param] = np.random.randint(min_val, max_val + 1)
            elif dtype == 'float':
                config[param] = np.random.uniform(min_val, max_val)

        return config

    def _generate_optimized_config(self, current_performance: Dict) -> Dict[str, Any]:
        """
        Genera configuraci√≥n optimizada basada en historial
        Usa meta-learning para identificar par√°metros m√°s importantes
        """
        if not self.best_config:
            return self._generate_random_config()

        # Partir de la mejor configuraci√≥n conocida
        config = copy.deepcopy(self.best_config)

        # Modificar 2-4 par√°metros basado en importancia
        num_changes = np.random.randint(2, 5)

        # Seleccionar par√°metros a modificar (priorizando los m√°s importantes)
        params_by_importance = sorted(
            self.parameter_importance.items(),
            key=lambda x: x[1],
            reverse=True
        )
        params_to_modify = [p[0] for p in params_by_importance[:num_changes]]

        # Modificar par√°metros seleccionados
        for param in params_to_modify:
            if param not in self.parameter_ranges:
                continue

            min_val, max_val, dtype = self.parameter_ranges[param]
            current_val = config.get(param, (min_val + max_val) / 2)

            # Perturbaci√≥n adaptativa (¬±20% del rango)
            range_size = max_val - min_val
            perturbation = np.random.uniform(-0.2, 0.2) * range_size

            if dtype == 'int':
                new_val = int(np.clip(current_val + perturbation, min_val, max_val))
            else:
                new_val = np.clip(current_val + perturbation, min_val, max_val)

            config[param] = new_val

        return config

    def _identify_changes(self, old_config: Dict, new_config: Dict) -> List[Dict]:
        """Identifica qu√© par√°metros cambiaron y en cu√°nto"""
        changes = []

        for param, new_val in new_config.items():
            old_val = old_config.get(param)
            if old_val != new_val:
                change_pct = 0
                if old_val and old_val != 0:
                    change_pct = ((new_val - old_val) / abs(old_val)) * 100

                changes.append({
                    'parameter': param,
                    'old_value': old_val,
                    'new_value': new_val,
                    'change_pct': change_pct
                })

        return changes

    def _generate_change_reason(self, changes: List[Dict], strategy: str,
                                performance: Dict) -> str:
        """
        Genera explicaci√≥n DETALLADA de por qu√© se hicieron los cambios
        Incluye: diagn√≥stico, objetivo, cambios espec√≠ficos, y expectativa de resultado
        """
        if not changes:
            return "Sin cambios - configuraci√≥n √≥ptima mantenida"

        win_rate = performance.get('win_rate', 0)
        roi = performance.get('roi', 0)
        sharpe = performance.get('sharpe_ratio', 0)
        drawdown = performance.get('max_drawdown', 0)
        total_trades = performance.get('total_trades', 0)

        reasons = []

        # SECCI√ìN 1: DIAGN√ìSTICO DE PERFORMANCE ACTUAL
        reasons.append("=== DIAGN√ìSTICO ===")

        # An√°lisis de win rate
        if win_rate < 40:
            reasons.append(f"‚ö†Ô∏è Win Rate CR√çTICO: {win_rate:.1f}% (objetivo: 50%+)")
            reasons.append("   ‚Üí Problema: Demasiados trades perdedores, se√±ales de baja calidad")
        elif win_rate < 50:
            reasons.append(f"‚ö†Ô∏è Win Rate BAJO: {win_rate:.1f}% (objetivo: 50%+)")
            reasons.append("   ‚Üí Necesita ajustar selectividad de se√±ales")
        elif win_rate > 70:
            reasons.append(f"‚úÖ Win Rate EXCELENTE: {win_rate:.1f}%")
            reasons.append("   ‚Üí Podemos ser m√°s agresivos para aumentar frecuencia")
        else:
            reasons.append(f"‚úÖ Win Rate SALUDABLE: {win_rate:.1f}%")

        # An√°lisis de ROI
        if roi < -5:
            reasons.append(f"üö® ROI MUY NEGATIVO: {roi:.2f}% - REDUCIR RIESGO URGENTE")
        elif roi < 0:
            reasons.append(f"‚ö†Ô∏è ROI NEGATIVO: {roi:.2f}% - Estrategia necesita ajustes")
        elif roi > 10:
            reasons.append(f"üéâ ROI EXCELENTE: {roi:.2f}% - Estrategia funcionando muy bien")
        else:
            reasons.append(f"ROI ACTUAL: {roi:.2f}%")

        # An√°lisis de drawdown
        if drawdown > 15:
            reasons.append(f"‚ö†Ô∏è Drawdown ALTO: {drawdown:.1f}% - Reducir tama√±o de posiciones")
        elif drawdown > 10:
            reasons.append(f"‚ö†Ô∏è Drawdown MODERADO: {drawdown:.1f}%")

        # SECCI√ìN 2: ESTRATEGIA Y OBJETIVO
        reasons.append("\n=== ESTRATEGIA ===")
        if strategy == "EXPLORATION":
            reasons.append("üîç EXPLORACI√ìN: Probando configuraciones nuevas para descubrir mejores setups")
            reasons.append(f"   ‚Üí Trials completados: {self.total_trials}")
            reasons.append("   ‚Üí Objetivo: Salir de √≥ptimos locales y encontrar mejores configuraciones")
        else:
            reasons.append("üéØ OPTIMIZACI√ìN: Refinando configuraci√≥n basado en resultados previos")
            reasons.append(f"   ‚Üí Usando aprendizajes de {len(self.trial_history)} trials anteriores")
            reasons.append("   ‚Üí Objetivo: Mejorar configuraci√≥n actual incrementalmente")

        # SECCI√ìN 3: CAMBIOS ESPEC√çFICOS CON RAZONAMIENTO
        reasons.append("\n=== CAMBIOS REALIZADOS ===")
        reasons.append(f"Total de par√°metros modificados: {len(changes)}\n")

        # Agrupar cambios por categor√≠a
        risk_changes = [c for c in changes if any(x in c['parameter'] for x in ['RISK', 'POSITION_SIZE', 'DRAWDOWN'])]
        indicator_changes = [c for c in changes if any(x in c['parameter'] for x in ['RSI', 'MACD', 'EMA', 'BB'])]
        threshold_changes = [c for c in changes if 'THRESHOLD' in c['parameter']]
        ml_changes = [c for c in changes if any(x in c['parameter'] for x in ['ESTIMATORS', 'DEPTH', 'LEARNING'])]

        if risk_changes:
            reasons.append("üìä GESTI√ìN DE RIESGO:")
            for change in risk_changes[:3]:  # Top 3
                param = change['parameter']
                old, new = change['old_value'], change['new_value']
                direction = "‚Üë" if new > old else "‚Üì"
                reasons.append(f"   {direction} {param}: {old} ‚Üí {new}")
                if 'POSITION_SIZE' in param:
                    if new > old:
                        reasons.append("      Raz√≥n: Incrementar exposici√≥n en mercado favorable")
                    else:
                        reasons.append("      Raz√≥n: Reducir exposici√≥n para proteger capital")

        if indicator_changes:
            reasons.append("\nüìà INDICADORES T√âCNICOS:")
            for change in indicator_changes[:3]:
                param = change['parameter']
                old, new = change['old_value'], change['new_value']
                direction = "‚Üë" if new > old else "‚Üì"
                reasons.append(f"   {direction} {param}: {old} ‚Üí {new}")
                if 'RSI' in param:
                    reasons.append("      Raz√≥n: Ajustar sensibilidad a sobrecompra/sobreventa")
                elif 'MACD' in param:
                    reasons.append("      Raz√≥n: Mejorar detecci√≥n de cambios de tendencia")

        if threshold_changes:
            reasons.append("\nüéØ UMBRALES DE SE√ëALES:")
            for change in threshold_changes[:3]:
                param = change['parameter']
                old, new = change['old_value'], change['new_value']
                direction = "‚Üë" if new > old else "‚Üì"
                reasons.append(f"   {direction} {param}: {old} ‚Üí {new}")
                if new > old:
                    reasons.append("      Raz√≥n: Aumentar selectividad - solo se√±ales de mayor calidad")
                else:
                    reasons.append("      Raz√≥n: Reducir selectividad - aumentar frecuencia de trades")

        if ml_changes:
            reasons.append("\nüß† MODELO MACHINE LEARNING:")
            for change in ml_changes[:2]:
                param = change['parameter']
                old, new = change['old_value'], change['new_value']
                reasons.append(f"   ‚Ä¢ {param}: {old} ‚Üí {new}")
            reasons.append("      Raz√≥n: Ajustar complejidad y capacidad de aprendizaje del modelo")

        # SECCI√ìN 4: EXPECTATIVA
        reasons.append("\n=== RESULTADO ESPERADO ===")
        if win_rate < 45:
            reasons.append("üéØ Objetivo inmediato: Aumentar win rate a 50%+")
            reasons.append("   ‚Üí Aumentando selectividad de se√±ales")
            reasons.append("   ‚Üí Mejorando precisi√≥n de indicadores")
        elif roi < 0:
            reasons.append("üéØ Objetivo inmediato: Revertir a ROI positivo")
            reasons.append("   ‚Üí Reduciendo tama√±o de posiciones")
            reasons.append("   ‚Üí Protegiendo capital con mejor gesti√≥n de riesgo")
        else:
            reasons.append("üéØ Objetivo: Optimizar estrategia exitosa para maximizar retornos")
            reasons.append("   ‚Üí Manteniendo lo que funciona")
            reasons.append("   ‚Üí Refinando par√°metros para mejor performance")

        return "\n".join(reasons)

    def record_trial_result(self, config: Dict, performance: Dict):
        """
        Registra resultado de un trial y actualiza aprendizaje

        Args:
            config: Configuraci√≥n probada
            performance: M√©tricas obtenidas
        """
        performance_score = self._calculate_performance_score(performance)

        # Guardar en historial
        self.trial_history.append({
            'trial_number': self.total_trials,
            'config': config,
            'performance': performance,
            'score': performance_score,
            'timestamp': datetime.now().isoformat()
        })

        # Actualizar mejor configuraci√≥n si super√≥ la anterior
        if performance_score > self.best_performance:
            improvement = performance_score - self.best_performance
            self.best_performance = performance_score
            self.best_config = copy.deepcopy(config)

            logger.info(
                f"üéâ NUEVA MEJOR CONFIGURACI√ìN! Score: {performance_score:.3f} "
                f"(+{improvement:.3f} mejora)"
            )

            # Notificaci√≥n especial para mejoras
            return {
                'improved': True,
                'improvement': improvement,
                'new_best_score': performance_score
            }

        # Actualizar importancia de par√°metros (meta-learning)
        self._update_parameter_importance(config, performance_score)

        return {
            'improved': False,
            'score': performance_score,
            'best_score': self.best_performance
        }

    def _update_parameter_importance(self, config: Dict, score: float):
        """
        Actualiza importancia de par√°metros basado en correlaci√≥n con performance
        Meta-learning: aprende qu√© par√°metros importan m√°s
        """
        if len(self.trial_history) < 5:
            return  # Necesita al menos 5 trials para aprender

        # Para cada par√°metro, calcular correlaci√≥n con score
        for param in self.parameter_ranges.keys():
            param_values = []
            scores = []

            for trial in self.trial_history[-20:]:  # √öltimos 20 trials
                if param in trial['config']:
                    param_values.append(trial['config'][param])
                    scores.append(trial['score'])

            if len(param_values) >= 5:
                # Filtrar valores inv√°lidos (inf, -inf, nan) antes de correlaci√≥n
                valid_indices = [
                    i for i, score in enumerate(scores)
                    if np.isfinite(score)  # Filtra inf, -inf, y nan
                ]

                if len(valid_indices) >= 5:  # Necesitamos al menos 5 valores v√°lidos
                    valid_param_values = [param_values[i] for i in valid_indices]
                    valid_scores = [scores[i] for i in valid_indices]

                    # Correlaci√≥n simple con valores v√°lidos
                    try:
                        correlation = np.corrcoef(valid_param_values, valid_scores)[0, 1]
                        if not np.isnan(correlation):
                            # Actualizar importancia (promedio m√≥vil)
                            self.parameter_importance[param] = (
                                0.7 * self.parameter_importance[param] +
                                0.3 * abs(correlation)
                            )
                    except (ValueError, RuntimeWarning):
                        # Si falla el c√°lculo, simplemente skip
                        pass

    def get_optimization_statistics(self) -> Dict:
        """Retorna estad√≠sticas del proceso de optimizaci√≥n"""
        if not self.trial_history:
            return {
                'total_trials': 0,
                'best_score': 0,
                'improvement_rate': 0,
                'top_parameters': []
            }

        # Calcular tasa de mejora
        recent_scores = [t['score'] for t in self.trial_history[-10:]]
        improvement_rate = np.mean(np.diff(recent_scores)) if len(recent_scores) > 1 else 0

        # Top par√°metros por importancia
        top_params = sorted(
            self.parameter_importance.items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]

        return {
            'total_trials': self.total_trials,
            'best_score': self.best_performance,
            'current_score': self.trial_history[-1]['score'] if self.trial_history else 0,
            'improvement_rate': improvement_rate,
            'top_parameters': top_params,
            'exploration_exhaustion': min(self.total_trials / 100.0, 1.0)  # 0-1
        }

    def save_to_dict(self) -> Dict:
        """Exporta optimizador para persistencia"""
        return {
            'trial_history': self.trial_history,
            'best_config': self.best_config,
            'best_performance': self.best_performance,
            'current_config': self.current_config,
            'total_trials': self.total_trials,
            'parameter_importance': self.parameter_importance,
            'timestamp': datetime.now().isoformat()
        }

    def load_from_dict(self, data: Dict):
        """Carga optimizador desde persistencia"""
        self.trial_history = data.get('trial_history', [])
        self.best_config = data.get('best_config', {})
        self.best_performance = data.get('best_performance', -float('inf'))
        self.current_config = data.get('current_config', {})
        self.total_trials = data.get('total_trials', 0)
        self.parameter_importance = data.get('parameter_importance', {})

        logger.info(
            f"‚úÖ Parameter Optimizer cargado: {self.total_trials} trials, "
            f"mejor score: {self.best_performance:.3f}"
        )
