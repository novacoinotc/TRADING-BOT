# ğŸ¤– Sistema AutÃ³nomo de Trading - Control Absoluto

## DescripciÃ³n

Sistema de IA completamente autÃ³nomo que tiene **CONTROL ABSOLUTO** sobre todos los parÃ¡metros y decisiones del bot de trading. La IA aprende, se optimiza y evoluciona sin intervenciÃ³n humana.

## Componentes Principales

### 1. **RL Agent** (`rl_agent.py`)
- **Reinforcement Learning** con Q-Learning
- Aprende de cada trade (recompensas/penalizaciones)
- Experience Replay para mejor aprendizaje
- Exploration vs Exploitation balanceado
- Almacena Q-Table con estados y acciones aprendidas

### 2. **Parameter Optimizer** (`parameter_optimizer.py`)
- OptimizaciÃ³n de **TODOS** los parÃ¡metros sin limitaciones
- Estrategias de exploraciÃ³n y optimizaciÃ³n
- Meta-learning: aprende quÃ© parÃ¡metros son mÃ¡s importantes
- BÃºsqueda inteligente basada en historial de performance
- **ParÃ¡metros optimizables:**
  - Trading: CHECK_INTERVAL, CONSERVATIVE_THRESHOLD, FLASH_THRESHOLD, etc.
  - Indicadores tÃ©cnicos: RSI_OVERSOLD, MACD_FAST, EMA_SHORT, etc.
  - Risk Management: BASE_POSITION_SIZE_PCT, MAX_DRAWDOWN_LIMIT, etc.
  - ML Hyperparameters: N_ESTIMATORS, MAX_DEPTH, LEARNING_RATE, etc.

### 3. **Learning Persistence** (`learning_persistence.py`)
- Guarda toda la inteligencia aprendida
- Sobrevive redeploys de Railway
- CompresiÃ³n de datos para eficiencia
- Backups automÃ¡ticos
- ExportaciÃ³n para fÃ¡cil importaciÃ³n
- ValidaciÃ³n de integridad (checksum)

### 4. **Autonomy Controller** (`autonomy_controller.py`)
- **Cerebro principal** del sistema
- Coordina todos los componentes
- Decide cuÃ¡ndo optimizar parÃ¡metros
- Notifica CADA cambio a Telegram
- Auto-save periÃ³dico de inteligencia
- GestiÃ³n completa del ciclo de vida

## CaracterÃ­sticas Clave

### ğŸ¯ Control Absoluto
- La IA puede modificar **CUALQUIER** parÃ¡metro
- Sin limitaciones ni restricciones humanas
- Decisiones basadas en resultados reales
- EvoluciÃ³n continua

### ğŸ“š Aprendizaje Continuo
- Aprende de cada trade ejecutado
- Mejora estrategia con el tiempo
- Meta-learning sobre importancia de parÃ¡metros
- Experience replay para mejor aprendizaje

### ğŸ’¾ Persistencia de Inteligencia
- **CRÃTICO**: Sobrevive redeploys
- Auto-save cada 30 minutos (configurable)
- Backups automÃ¡ticos
- Archivo de exportaciÃ³n para importar despuÃ©s de redeploy

### ğŸ”” Notificaciones Transparentes
- Cada modificaciÃ³n es notificada a Telegram
- Explica **por quÃ©** cambiÃ³ parÃ¡metros
- Reporta mejoras encontradas
- Status de aprendizaje

## Flujo de Funcionamiento

```
1. Bot inicia â†’ Carga inteligencia previa (si existe)
                â†“
2. Trades ejecutados â†’ RL Agent aprende
                â†“
3. Cada N trades â†’ Parameter Optimizer sugiere cambios
                â†“
4. Cambios aplicados â†’ Telegram notificado
                â†“
5. Performance medido â†’ RL Agent y Optimizer actualizados
                â†“
6. Auto-save periÃ³dico â†’ Inteligencia guardada
                â†“
7. Ciclo se repite â†’ IA mejora continuamente
```

## ConfiguraciÃ³n

En `config/config.py` o variables de entorno:

```python
# Habilitar modo autÃ³nomo
ENABLE_AUTONOMOUS_MODE = true  # Â¡ACTIVAR PARA CONTROL TOTAL!

# Auto-save (minutos)
AUTONOMOUS_AUTO_SAVE_INTERVAL = 30

# Intervalo de optimizaciÃ³n (horas)
AUTONOMOUS_OPTIMIZATION_INTERVAL = 2.0

# MÃ­nimo trades antes de optimizar
AUTONOMOUS_MIN_TRADES_BEFORE_OPT = 20
```

## IntegraciÃ³n

### En `main.py`
```python
# Sistema autÃ³nomo se inicializa automÃ¡ticamente si estÃ¡ habilitado
autonomy_controller = AutonomyController(
    telegram_notifier=monitor.notifier,
    auto_save_interval_minutes=30,
    optimization_check_interval_hours=2.0,
    min_trades_before_optimization=20
)
await autonomy_controller.initialize()
```

### En `market_monitor.py`
- Trades cerrados se envÃ­an al controller para aprendizaje
- RL Agent aprende de outcomes
- Parameter Optimizer ajusta configuraciÃ³n

## Archivos de Persistencia

### UbicaciÃ³n
`data/autonomous/`

### Archivos generados
- `learned_intelligence.json.gz` - Inteligencia comprimida (principal)
- `learned_intelligence_backup.json.gz` - Backup automÃ¡tico
- `intelligence_export.json` - Export legible para importar
- `intelligence_export_YYYYMMDD_HHMMSS.json` - Exports timestamped

### Contenido guardado
```json
{
  "version": "1.0",
  "timestamp": "2025-11-01T...",
  "rl_agent": {
    "q_table": {...},  // Estados y acciones aprendidas
    "statistics": {...},  // Stats del agente
    "episode_rewards": [...]
  },
  "parameter_optimizer": {
    "trial_history": [...],  // Historial de trials
    "best_config": {...},  // Mejor configuraciÃ³n encontrada
    "parameter_importance": {...}  // Importancia de cada parÃ¡metro
  },
  "performance_history": {...},  // Ãšltimos 100 trades
  "metadata": {
    "current_parameters": {...},  // ParÃ¡metros actuales
    "total_trades_processed": 1234,
    "total_parameter_changes": 42
  }
}
```

## Importar Inteligencia DespuÃ©s de Redeploy

### OpciÃ³n 1: AutomÃ¡tica
El sistema carga automÃ¡ticamente `data/autonomous/learned_intelligence.json.gz` al iniciar.

### OpciÃ³n 2: Manual
```python
from src.autonomous.learning_persistence import LearningPersistence

persistence = LearningPersistence()
persistence.import_from_file('path/to/intelligence_export.json')
```

## Notificaciones de Telegram

El sistema envÃ­a notificaciones para:

### Al iniciar
- âœ… Inteligencia cargada (si existe)
- ğŸ†• Primera ejecuciÃ³n (si es nuevo)

### Durante operaciÃ³n
- ğŸ¤– ParÃ¡metros modificados (cada cambio)
- ğŸ‰ Trade exitoso aprendido (profit > 2%)
- ğŸ“š Trade perdedor analizado (loss < -2%)
- ğŸ‰ Nueva mejor configuraciÃ³n encontrada

### Al apagar
- ğŸ›‘ Resumen de sesiÃ³n
- ğŸ“Š Trades procesados
- ğŸ”§ Cambios realizados

## Estrategias de OptimizaciÃ³n

### ExploraciÃ³n (30%)
- Cambios aleatorios
- Descubre nuevas configuraciones
- Importante al inicio

### OptimizaciÃ³n (70%)
- Basado en mejores resultados previos
- Modifica 2-4 parÃ¡metros mÃ¡s importantes
- Perturbaciones adaptativas (Â±20%)

### Meta-Learning
- Aprende quÃ© parÃ¡metros tienen mayor impacto
- Prioriza modificar parÃ¡metros importantes
- Actualiza importancia con correlaciones

## MÃ©tricas de Performance

El sistema considera:
- **Win Rate** (25% peso)
- **ROI** (30% peso)
- **Sharpe Ratio** (15% peso)
- **Profit Factor** (20% peso)
- **Max Drawdown** (10% peso, invertido)

Score total = Suma ponderada de mÃ©tricas

## Intervenciones AutomÃ¡ticas

La IA optimiza cuando:
1. â° Intervalo de tiempo alcanzado (2 horas)
2. ğŸ“Š Suficientes trades procesados (20+)
3. âš ï¸ Win rate crÃ­tico (< 35%)
4. âš ï¸ ROI crÃ­tico (< -10%)
5. ğŸ¯ Win rate excelente (> 65%) - maximizar

## Limitaciones y Consideraciones

### Railway (sin Volumes)
- Los archivos en `data/autonomous/` se pierden en redeploy
- **SoluciÃ³n**: Git commit de archivos de inteligencia antes de redeploy
- O descargar `intelligence_export.json` manualmente

### Con Volumes (Railway Pro+)
- Persistencia automÃ¡tica total
- Sin necesidad de commits manuales

## Desarrollo Futuro

Posibles mejoras:
- [ ] Algoritmos mÃ¡s avanzados (PPO, A3C)
- [ ] Multi-armed bandits
- [ ] Bayesian Optimization
- [ ] Auto-tuning de hyperparameters del RL Agent
- [ ] Ensemble de estrategias
- [ ] Transfer learning entre pares

## Logs y Debugging

```bash
# Ver logs del sistema autÃ³nomo
tail -f logs/trading_bot.log | grep -E "(ğŸ¤–|ğŸ§ |ğŸ¯|ğŸ’¾)"

# Verificar archivos de persistencia
ls -lh data/autonomous/

# Ver contenido de inteligencia guardada
cat data/autonomous/intelligence_export.json | jq
```

## Preguntas Frecuentes

### Â¿QuÃ© pasa si el bot crashea?
Auto-save cada 30 min garantiza que mÃ¡ximo se pierden 30 min de aprendizaje.

### Â¿CÃ³mo sÃ© quÃ© estÃ¡ cambiando la IA?
Cada cambio es notificado a Telegram con explicaciÃ³n detallada.

### Â¿Puedo desactivar el modo autÃ³nomo?
SÃ­, en Railway variables: `ENABLE_AUTONOMOUS_MODE=false`

### Â¿CuÃ¡nto tiempo tarda en aprender?
- Primeras mejoras: ~50-100 trades
- OptimizaciÃ³n significativa: ~500-1000 trades
- Madurez: ~2000+ trades (1-2 meses)

### Â¿Puedo modificar parÃ¡metros manualmente?
SÃ­, pero la IA los sobrescribirÃ¡ en prÃ³xima optimizaciÃ³n.

## Autor

Sistema diseÃ±ado para **control absoluto** y **aprendizaje continuo** sin intervenciÃ³n humana.

**Modo**: AUTONOMÃA TOTAL âœ¨
